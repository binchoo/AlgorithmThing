{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python 계산 모델\n",
    "\n",
    "1. `리스트`는 파이썬의 배열 구현이다. 따라서 Random Access Machine이다.\n",
    "2. `객체`가 상수 개의 속성을 지닌다면 이는 Pointer Machine이다.\n",
    "\n",
    "### Python 계산 비용\n",
    "\n",
    "1. list\n",
    "\n",
    "   파이썬의 배열 구현임\n",
    "\n",
    "   - append : O(1)\n",
    "\n",
    "   - concat : O(1 + n+m)\n",
    "\n",
    "     L1과  L2를 합쳐 새로운 리스트로 만드는 걔념이다.\n",
    "\n",
    "   - extend : O(m)\n",
    "\n",
    "     L1의 뒤에 L2를 붙이는 개념이다\n",
    "\n",
    "   - slice :  O(j - i + 1)\n",
    "\n",
    "   - has : O(n)\n",
    "\n",
    "   - len : O(1)\n",
    "\n",
    "   - sort : O(nlogn)\n",
    "\n",
    "2. tuple, str\n",
    "\n",
    "   Immutable한 list로 보면 된다.\n",
    "\n",
    "3. dict\n",
    "\n",
    "   파이썬의 해시테이블 구현이다.\n",
    "\n",
    "4. set\n",
    "\n",
    "   val 없는 dict와 같다\n",
    "\n",
    "5. heapq\n",
    "\n",
    "   STL에 구현된 힙이다.\n",
    "\n",
    "   - push : O(logn)\n",
    "   - pop : O(logn)\n",
    "\n",
    "6. long\n",
    "\n",
    "   크기가 큰 정수자료이다.\n",
    "\n",
    "   - x + y = O(|x| + |y|)\n",
    "   - x * y = O((|x| + |y|)^lg3)\n",
    "\n",
    "## 예제 : 문서 거리 계산하기\n",
    "\n",
    "#### 목적 : 두 문서의 거리 $d(D_1, D_2)$를 계산하라.\n",
    "\n",
    "#### 응용 : 위키에서 중복 문서를 발견. 쿼리 $D_2$에 대응하는 문서 검색.\n",
    "\n",
    "#### 개념\n",
    "\n",
    "- word는 알파벳의 연속이다 = list of character\n",
    "- document는 word의 연속이다 = list of word\n",
    "- distance는 공통된 word가 많을 수록 짧아진다.\n",
    "- 문서 D에서 D[w]는 w가 등장하는 빈도이다 = 문서 D는 단어 빈도 벡터\n",
    "\n",
    "#### 해결 방법\n",
    "\n",
    "- 두 벡터의 방향이 비슷하면 사이각이 작다\n",
    "\n",
    "- scale invariant 하도록 정규화한다.\n",
    "  $$\n",
    "  d_{1,2} = \\arccos( {{D_1 \\cdot D_2} \\over {|D_1||D_2|}})\n",
    "  $$\n",
    "\n",
    "#### 알고리즘\n",
    "\n",
    "단어 빈도 벡터 D를 만드는 것이 핵심. \n",
    "\n",
    "1. 문서를 단어 별로 쪼갠다.\n",
    "\n",
    "   a. 정규표현식을 사용할까? O(exp)\n",
    "\n",
    "   b. char를 훑으면서 !isalphanum 마다 쪼갤까? O(|doc|)\n",
    "\n",
    "2. 각 단어의 빈도를 센다.\n",
    "\n",
    "   a. 애초에 딕셔너리를 사용하거나\n",
    "\n",
    "   b. word 리스트를 만들어 **정렬**하고, 이전 word와 같을 카운터 증가. 다를 경우 이전 word와 카운터를 자료구조에 저장한다.\n",
    "\n",
    "3. 내적 값을 구한다.\n",
    "\n",
    "   0이 아닐 경우에만 연산시켜라\n",
    "\n",
    "   a. 문서 A의 한 word마다 상대 문서에서 word가 있는지 검사하여 내적\n",
    "\n",
    "   b. **정렬된 상태를 이용**하여, 양측 워드 리스트의 지시자를 옮기면서 내적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordvec_from_file(filename) :\n",
    "    L = get_filelines(filename)\n",
    "    wordvec = {}\n",
    "    for line in L :\n",
    "        wordvec_from_string(wordvec, line)\n",
    "    return wordvec\n",
    "\n",
    "def get_filelines(filename) :\n",
    "    try :\n",
    "        f = open(filename, 'r')\n",
    "        return f.readlines();\n",
    "    except IOError :\n",
    "        print(\"Error has been occured opening file :\", filename)\n",
    "        sys.exit();\n",
    "        \n",
    "def wordvec_from_string(wordvec, line) :\n",
    "    word = \"\"\n",
    "    for c in line :\n",
    "        if c.isalnum() :\n",
    "            word += c\n",
    "        elif len(word) > 0 :\n",
    "            word = word.lower()\n",
    "            increase_word_counter(wordvec, word)\n",
    "            word = \"\"\n",
    "    if len(word) > 0 :\n",
    "        word = word.lower()\n",
    "        increase_word_counter(wordvec, word)\n",
    "    \n",
    "def increase_word_counter(wordvec, word) :\n",
    "    try :\n",
    "        wordvec[word] += 1\n",
    "    except :\n",
    "        wordvec[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "D1 = wordvec_from_file(\"./data/t1.verne.txt\")\n",
    "D2 = wordvec_from_file(\"./data/t2.bobsey.txt\")\n",
    "D3 = wordvec_from_file(\"./data/t3.lewis.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordvec_innerproduct(D1, D2) :\n",
    "    summation = 0\n",
    "    for word in D1.keys() :\n",
    "        if word in D2.keys() :\n",
    "            summation += D1[word] * D2[word]\n",
    "    return summation\n",
    "\n",
    "def wordvec_distance(D1, D2) :\n",
    "    denorm = wordvec_innerproduct(D1, D2)\n",
    "    norm = denorm / math.sqrt(wordvec_innerproduct(D1, D1) * wordvec_innerproduct(D2, D2))\n",
    "    return math.acos(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_distance(D1, D1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5829494425772849"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_distance(D1, D2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42184872505837584"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_distance(D1, D3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_distance(D2, D2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5741596010646867"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_distance(D2, D3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_distance(D3, D3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same0 = wordvec_from_file(\"./data/same0\")\n",
    "same1 = wordvec_from_file(\"./data/same1\")\n",
    "wordvec_distance(same0, same1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
